#!/usr/bin/env python3
"""
{{ tool_name }} - {{ tool_description }}

Generated by Amplifier Microtask Pipeline
"""

import click
import asyncio
import json
from pathlib import Path
from typing import Dict, List, Any, Optional

{{ validation_code }}

# Core functionality imports
{% if "ai_integration" in components %}
from claude_code_sdk import ClaudeSDKClient, ClaudeCodeOptions
{% endif %}
{% if "file_io" in components %}
# File I/O utilities (embedded for portability)
def write_json(data: Any, filepath: Path):
    """Write JSON data to file."""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    with filepath.open('w') as f:
        json.dump(data, f, indent=2)

def read_json(filepath: Path) -> Any:
    """Read JSON data from file."""
    with filepath.open('r') as f:
        return json.load(f)
{% endif %}

@click.group()
def cli():
    """{{ tool_description }}"""
    pass


@cli.command()
@click.option("--input", "-i", required=True, help="Input file or directory")
@click.option("--output", "-o", default="{{ default_output_dir }}", help="Output directory")
{% for option in custom_options %}
@click.option("--{{ option.name }}", default={{ option.default | tojson }}, help="{{ option.help }}")
{% endfor %}
def process(input: str, output: str{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %}):
    """Process {{ tool_name }} task."""
    # Convert to Path objects
    input_path = Path(input)
    output_path = Path(output)

    # Validate input
    if not input_path.exists():
        click.echo(f"Error: Input path '{input}' does not exist", err=True)
        return 1

    # Create output directory
    output_path.mkdir(parents=True, exist_ok=True)

    # Run the processing
    {% if "async_processing" in components %}
    asyncio.run(process_async(input_path, output_path{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %}))
    {% else %}
    process_sync(input_path, output_path{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %})
    {% endif %}

    click.echo(f"✅ Processing complete. Results saved to {output_path}")
    return 0


{% if "async_processing" in components %}
async def process_async(input_path: Path, output_path: Path{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %}):
    """Async processing implementation."""
    {% if "incremental_processor" in components %}
    # Load existing results for resume capability
    results_file = output_path / "results.json"
    results = load_results(results_file) if results_file.exists() else {}
    {% endif %}

    # Get items to process
    items = get_items_to_process(input_path{% if "incremental_processor" in components %}, results{% endif %})

    # Process each item
    for idx, item in enumerate(items, 1):
        click.echo(f"[{idx}/{len(items)}] Processing {item.get('name', item.get('id', 'item'))}...")

        {% if "incremental_processor" in components %}
        # Skip if already processed
        if item.get('id') in results:
            click.echo(f"  ⏭️  Already processed, skipping")
            continue
        {% endif %}

        # Process the item
        {% if "ai_integration" in components %}
        result = await process_item_with_ai(item{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %})
        {% else %}
        result = await process_item(item{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %})
        {% endif %}

        {% if "incremental_processor" in components %}
        # Save immediately for incremental progress
        results[item.get('id')] = result
        save_results(results, results_file)
        {% endif %}

        click.echo(f"  ✓ Processed successfully")

    {% if not "incremental_processor" in components %}
    # Save all results at once
    save_results(results, output_path / "results.json")
    {% endif %}
{% else %}
def process_sync(input_path: Path, output_path: Path{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %}):
    """Synchronous processing implementation."""
    # Implementation for non-async processing
    pass
{% endif %}


def get_items_to_process(input_path: Path{% if "incremental_processor" in components %}, existing_results: Dict{% endif %}) -> List[Dict]:
    """Get list of items to process from input."""
    items = []

    if input_path.is_file():
        # Process single file
        items.append({
            'id': input_path.stem,
            'path': str(input_path),
            'name': input_path.name
        })
    elif input_path.is_dir():
        # Process directory of files
        for file_path in sorted(input_path.glob("{{ input_pattern }}")):
            {% if "incremental_processor" in components %}
            # Skip if already processed
            if file_path.stem in existing_results:
                continue
            {% endif %}
            items.append({
                'id': file_path.stem,
                'path': str(file_path),
                'name': file_path.name
            })

    return items


{% if "ai_integration" in components %}
async def process_item_with_ai(item: Dict[str, Any]{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %}) -> Dict[str, Any]:
    """Process an item using Claude SDK with validation."""
    try:
        # Read the item content
        content = Path(item['path']).read_text()

        # Process with AI
        async with asyncio.timeout(120):  # 120 second timeout per DISCOVERIES.md
            async with ClaudeSDKClient(
                options=ClaudeCodeOptions(
                    system_prompt={{ ai_system_prompt }},
                    max_turns=1,
                )
            ) as client:
                await client.query(f"""{{ ai_prompt_template | safe }}

Content:
{content}

Important: Return ONLY the JSON response, no preambles or explanations.
""")

                # Collect response
                response = ""
                async for message in client.receive_response():
                    if hasattr(message, "content"):
                        content_obj = getattr(message, "content", [])
                        if isinstance(content_obj, list):
                            for block in content_obj:
                                if hasattr(block, "text"):
                                    response += getattr(block, "text", "")

                # Validate response
                is_valid, error_msg, parsed_data = validate_ai_response(response, item['name'])

                if not is_valid:
                    click.echo(f"  ❌ Validation failed: {error_msg}")
                    return {'error': 'validation_failed', 'message': error_msg, 'source': item['name']}

                # Add source metadata
                parsed_data['source'] = item['name']

                # Validate result structure
                result_valid, result_error = validate_processing_result(parsed_data)
                if not result_valid:
                    click.echo(f"  ⚠️  Result validation warning: {result_error}")

                return parsed_data

    except asyncio.TimeoutError:
        click.echo(f"  ⚠️  AI processing timed out for {item['name']}", err=True)
        return {'error': 'timeout', 'source': item['name']}
    except Exception as e:
        click.echo(f"  ❌ Error processing {item['name']}: {e}", err=True)
        return {'error': str(e), 'source': item['name']}


# Note: parse_ai_response functionality is now integrated into validate_ai_response
{% else %}
async def process_item(item: Dict[str, Any]{% for option in custom_options %}, {{ option.name|replace('-', '_') }}{% endfor %}) -> Dict[str, Any]:
    """Process a single item."""
    # TODO: Implement processing logic
    content = Path(item['path']).read_text()

    # Example processing
    result = {
        'source': item['name'],
        'processed': True,
        'length': len(content),
        'data': {}  # Ensure there's content beyond metadata
    }

    # Validate result structure
    is_valid, error_msg = validate_processing_result(result)
    if not is_valid:
        click.echo(f"  ⚠️  Warning: {error_msg}")

    return result
{% endif %}


{% if "incremental_processor" in components %}
def load_results(results_file: Path) -> Dict[str, Any]:
    """Load existing results for resume capability."""
    if results_file.exists():
        with results_file.open('r') as f:
            return json.load(f)
    return {}


def save_results(results: Dict[str, Any], results_file: Path):
    """Save results immediately for incremental progress."""
    results_file.parent.mkdir(parents=True, exist_ok=True)
    with results_file.open('w') as f:
        json.dump(results, f, indent=2)
{% endif %}


@cli.command()
def status():
    """Show processing status."""
    output_dir = Path("{{ default_output_dir }}")
    if not output_dir.exists():
        click.echo("No output directory found. Run 'process' first.")
        return

    results_file = output_dir / "results.json"
    if not results_file.exists():
        click.echo("No results found. Run 'process' first.")
        return

    {% if "incremental_processor" in components %}
    results = load_results(results_file)
    {% else %}
    with results_file.open('r') as f:
        results = json.load(f)
    {% endif %}
    total = len(results)
    errors = sum(1 for r in results.values() if 'error' in r)
    validation_failures = sum(1 for r in results.values() if r.get('error') == 'validation_failed')
    successful = total - errors

    click.echo(f"Processing Status:")
    click.echo(f"  ✓ Successful: {successful}")
    click.echo(f"  ✗ Errors: {errors}")
    if validation_failures > 0:
        click.echo(f"    - Validation failures: {validation_failures}")
    click.echo(f"  Total: {total}")


@cli.command()
def version():
    """Show tool version."""
    click.echo("{{ tool_name }} v{{ tool_version }}")


if __name__ == "__main__":
    cli()