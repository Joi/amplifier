from __future__ import annotations

import json


def compose_recipes_from_plan(tool_name: str, plan_text: str) -> str:
    """Compose a self-contained recipes module from a JSON PLAN.

    Built line-by-line to avoid quoting/indentation pitfalls. No fallbacks:
    missing/empty PLAN causes a runtime error in the generated run().
    """
    try:
        plan_obj = json.loads(plan_text)
    except Exception:
        plan_obj = {}
    plan_literal = json.dumps(plan_obj)

    lines: list[str] = []
    a = lines.append
    a("from __future__ import annotations")
    a("")
    a("import json")
    a("import re")
    a("from pathlib import Path")
    a("from typing import Any")
    a("")
    a("from .llm import complete")
    a("")
    a(f"PLAN = json.loads({repr(plan_literal)})")
    a("")
    a("def _w(path: Path, text: str) -> None:")
    a("    path.parent.mkdir(parents=True, exist_ok=True)")
    a("    path.write_text(text, encoding='utf-8')")
    a("")
    a("def _r(path: Path) -> str:")
    a("    return path.read_text(encoding='utf-8', errors='ignore')")
    a("")
    a("def step_discover_markdown(art: Path, src_dir: Path, limit: int) -> dict[str, Any]:")
    a("    files = sorted(src_dir.glob('*.md'))[:limit]")
    a("    (art / 'discover.json').write_text(json.dumps([str(p) for p in files], indent=2))")
    a("    return {'files': [str(p) for p in files]}")
    a("")
    a("def step_extract_structured(art: Path, work: Path, schema: list[str]) -> dict[str, Any]:")
    a("    files = json.loads((art / 'discover.json').read_text()) if (art / 'discover.json').exists() else []")
    a("    out_dir = work / 'findings'")
    a("    out_dir.mkdir(parents=True, exist_ok=True)")
    a("    index: list[str] = []")
    a("    for p in files:")
    a("        path = Path(p)")
    a("        out = out_dir / f'{path.stem}.json'")
    a("        if out.exists():")
    a("            index.append(str(out))")
    a("            continue")
    a("        text = _r(path)")
    a("        keys = ', '.join(schema)")
    a("        prompt = (")
    a("            'Extract the following lists as JSON keys [' + keys + '] from the document.\\n' ")
    a("            'Return ONLY JSON with those keys, each an array of terse strings.\\n\\n' + text")
    a("        )")
    a("        raw = complete(prompt, role='analysis expert')")
    a("        data = {k: [] for k in schema}")
    a("        try:")
    a("            m = re.search(r'```json\\s*(.*?)```', raw, flags=re.S | re.I)")
    a("            block = m.group(1) if m else raw")
    a("            data = json.loads(block)")
    a("        except Exception:")
    a("            pass")
    a("        out.write_text(json.dumps(data, indent=2))")
    a("        index.append(str(out))")
    a("    (art / 'findings.json').write_text(json.dumps(index, indent=2))")
    a("    return {'findings': index}")
    a("")
    a("def step_synthesize_catalog(art: Path) -> dict[str, Any]:")
    a("    index = json.loads((art / 'findings.json').read_text()) if (art / 'findings.json').exists() else []")
    a("    items = []")
    a("    for f in index:")
    a("        try:")
    a("            items.append({'path': f, 'data': json.loads(Path(f).read_text())})")
    a("        except Exception:")
    a("            items.append({'path': f, 'data': {}})")
    a("    prompt = (")
    a("        'Build a deduplicated requirements catalog from the items below. ' ")
    a("        'Each entry must be {id, title, rationale, sources[list of paths]} and id must be stable.\\n\\n' ")
    a("        + json.dumps(items)[:90000]")
    a("    )")
    a("    raw = complete(prompt, role='synthesis master')")
    a("    catalog: list[dict] = []")
    a("    try:")
    a("        m = re.search(r'```json\\s*(.*?)```', raw, flags=re.S | re.I)")
    a("        block = m.group(1) if m else raw")
    a("        catalog = json.loads(block)")
    a("    except Exception:")
    a("        catalog = []")
    a("    (art / 'catalog.json').write_text(json.dumps(catalog, indent=2))")
    a("    return {'catalog_count': len(catalog)}")
    a("")
    a("def step_draft_blueprints(art: Path, work: Path) -> dict[str, Any]:")
    a("    catalog = json.loads((art / 'catalog.json').read_text()) if (art / 'catalog.json').exists() else []")
    a("    out_dir = work / 'blueprints'")
    a("    out_dir.mkdir(parents=True, exist_ok=True)")
    a("    written = 0")
    a("    for i, item in enumerate(catalog, 1):")
    a("        name = item.get('title') or ('item_%03d' % i)")
    a("        outfile = out_dir / (name.replace(' ', '_').lower() + '.md')")
    a("        if outfile.exists():")
    a("            continue")
    a("        rationale = item.get('rationale', '')")
    a("        sources = '\\n'.join(item.get('sources', []))")
    a("        prompt = (")
    a("            'Item: ' + name + '\\n\\nRationale: ' + rationale + '\\n\\n' ")
    a(
        "            'Draft a blueprint with sections: ## Context, ## Interfaces, ## Risks, ## Test Strategy, ## Milestones. ' "
    )
    a("            'Reference source filenames where appropriate.\\n\\nSources:\\n' + sources")
    a("        )")
    a("        text = complete(prompt, role='modular builder')")
    a("        if text.count('## ') < 3 or len(text) < 600:")
    a(
        "            critique = complete('Critique this blueprint; list missing sections and weak depth.', role='analysis expert')"
    )
    a(
        "            text = complete('Improve the blueprint using these fixes. Return only improved markdown.\\nFixes:\\n' + critique + '\\n\\n' + text, role='synthesis master')"
    )
    a("        outfile.write_text(text)")
    a("        written += 1")
    a("    return {'blueprints': written}")
    a("")
    a("def run(src: str, *, limit: int = 5, work: str | None = None, on_event=None) -> dict[str, Any]:")
    a("    from .orchestrator import Orchestrator")
    a("")
    a("    srcp = Path(src)")
    a(f"    workp = Path(work) if work else Path('.data') / '{tool_name}' / 'compose_work'")
    a(f"    orch = Orchestrator(Path('.data') / '{tool_name}' / 'runs')")
    a("")
    a("    if not isinstance(PLAN, dict) or not PLAN.get('steps'):")
    a("        raise ValueError('PLAN missing or empty: no steps to run (no fallbacks)')")
    a("    steps_cfg = PLAN['steps']")
    a("")
    a("    def _resolve(step: dict[str, Any]):")
    a("        kind = step.get('kind')")
    a("        params = step.get('params') or {}")
    a("        if kind == 'discover_markdown':")
    a("            _lv = params.get('limit')")
    a("            try:")
    a("                lim = int(_lv) if _lv is not None else limit")
    a("            except Exception:")
    a("                lim = limit")
    a("            return ('discover', lambda art: step_discover_markdown(art, srcp, lim))")
    a("        if kind == 'extract_structured':")
    a("            schema = list(params.get('schema') or ['features','constraints','acceptance_criteria'])")
    a("            return ('extract_structured', lambda art: step_extract_structured(art, workp, schema))")
    a("        if kind == 'synthesize_catalog':")
    a("            return ('synthesize_catalog', lambda art: step_synthesize_catalog(art))")
    a("        if kind == 'draft_blueprints':")
    a("            return ('draft_blueprints', lambda art: step_draft_blueprints(art, workp))")
    a("        raise ValueError('Unknown step kind: ' + str(kind))")
    a("")
    a("    steps = [_resolve(s) for s in steps_cfg]")
    a("    s = orch.run('compose', steps, on_event)")
    a("    return {")
    a("        'job_id': s.job_id,")
    a("        'recipe': s.recipe,")
    a("        'success': True,")
    a(f"        'artifacts_dir': str((Path('.data') / '{tool_name}' / 'runs' / s.job_id / 'artifacts').resolve()),")
    a("    }")

    return "\n".join(lines) + "\n"
