# Claude Code Agent Loop: Technical Architecture and Implementation

Claude Code operates through a deceptively simple single-threaded master loop architecture that continuously cycles through tool execution, result processing, and decision-making until tasks complete. **The core loop follows a straightforward pattern: while tool calls are needed, execute the tool, feed results back to Claude, and repeat until Claude produces a plain text response without tool calls.** This design philosophy prioritizes debuggability and reliability over architectural complexity, achieving sophisticated autonomous behavior through constraint-driven simplicity rather than multi-agent orchestration.

The agent loop's power emerges from its structured four-phase cycle—**gather context → take action → verify work → repeat**—combined with 14 specialized tools, automatic context management, and multi-layered safety mechanisms. According to official Anthropic documentation at docs.claude.com, this same agent harness powers both the Claude Code CLI tool and the Claude Agent SDK, enabling developers to build production-ready agents using battle-tested infrastructure. The system achieves state-of-the-art performance on SWE-bench Verified while maintaining complete transparency through diff-based workflows and comprehensive audit trails.

## The master loop architecture runs on radical simplicity

Claude Code implements what Anthropic internally calls the "nO" master loop—a single-threaded execution pattern that maintains one flat message history without complex threading or agent swarms. The fundamental architecture consists of the user providing a prompt, Claude deciding to use tools (returning a stop_reason of "tool_use"), the application executing those tools, and results feeding back to Claude in a continuous cycle. This repetition of tool use requests and result evaluation without additional user input defines the core "agent loop" that powers all Claude Code operations.

The architectural design deliberately avoids complexity through several key constraints. The system permits **maximum one sub-agent branch at a time** to prevent uncontrolled agent proliferation, and sub-agents themselves cannot spawn additional sub-agents, preventing recursive explosion. The loop terminates naturally when Claude produces plain text without tool calls, cleanly returning control to the user for the next input. This single-threaded approach was explicitly chosen by Anthropic for **debuggability and reliability** over sophisticated multi-agent swarms, as articulated in their official best practices documentation.

Supporting this main loop is the h2A asynchronous dual-buffer message queue, which enables real-time steering capabilities. Users can pause execution, inject new instructions mid-task, and seamlessly adjust plans without full restarts. This transforms Claude Code from a batch processing system into a dynamic coding partner where developers provide real-time guidance and corrections. During complex refactoring, for instance, users can realize they need additional constraints and inject new instructions into the queue, with Claude adjusting its approach without losing context or restarting the entire operation.

## Each loop iteration follows a structured four-phase pattern

The agent loop operates through four distinct phases that repeat until task completion. The **gather context phase** involves searching and discovering relevant information through agentic search, accessing the file system, loading code and documentation, and reading the current state. Unlike traditional RAG-based approaches, Claude Code performs on-demand searches using grep, find, and glob commands exactly as human developers would, with the LLM constructing sophisticated regex patterns to find relevant code. This approach eliminates hidden failure modes from similarity functions, reranking strategies, and chunking while remaining RL-learnable and benefiting directly from model improvements.

During the **take action phase**, Claude executes tools based on its reasoning—modifying files through Edit, Write, or Replace tools; running commands via the Bash tool; invoking external services through Model Context Protocol (MCP) integrations; or spawning sub-agents for complex sub-tasks. The system provides 14 core tools organized into file system operations (Read, Write, Edit, MultiEdit, NotebookRead, NotebookEdit), command line tools (Bash, Glob, Grep, Ls), web tools (WebSearch, WebFetch), and control flow tools (TodoWrite, Task). Each tool follows a consistent pattern of JSON tool calls executing in sandboxed environments and returning plain text results.

The **verify work phase** ensures quality through multiple mechanisms. Claude runs tests to validate changes, checks lint errors for code quality, executes commands to verify functionality, uses visual feedback like screenshots for UI work, and applies rules-based validation. This verification is critical to the agent loop's effectiveness—according to Anthropic's internal observations, 2-3 iterations typically produce significantly better results than first attempts, with the verification phase providing the feedback necessary for iterative refinement.

The **repeat phase** drives continuous improvement as Claude iterates based on verification results, continuing until success criteria are met, adjusting approaches based on failures, and updating TODO lists to track progress. This iterative pattern embraces self-correction as a first-class citizen in the development workflow, with clear targets like tests, visual mocks, and output validation guiding each iteration.

## Tool selection balances abstraction levels for optimal accuracy

Claude Code's tool design follows a deliberate frequency-driven strategy that trades off between abstraction level and usage accuracy. The system provides **low-level tools** like Bash, Read, and Write for generic flexibility; **medium-level tools** like Edit, Grep, and Glob for frequently used operations that justify dedicated implementations; and **high-level tools** like Task, WebFetch, and exit_plan_mode for extremely deterministic operations that save the LLM from executing multiple low-level steps.

The decision to implement Grep as a dedicated tool rather than relying solely on Bash commands exemplifies this philosophy. Grep sees sufficiently frequent use that a specialized tool improves accuracy, and the LLM demonstrates deep enough understanding of code structure to craft sophisticated ripgrep-powered regex patterns. This mirrors how human developers work, performing complex searches with ripgrep, jq, and find rather than relying on semantic similarity. The tool selection criteria balance frequency of use, required determinism, and the accuracy trade-off between how often an agent uses a tool versus how accurately it uses it.

Tool descriptions consume approximately **9,400 tokens in the system prompt**, with each tool receiving elaborate documentation including examples, heuristics, and decision-making guidance. The Edit tool emerges as the most frequently used for surgical code changes, followed by Read for context gathering, TodoWrite for planning, Bash for command execution, and Grep for code search. This usage pattern informed the tool design decisions, with frequently-used operations receiving dedicated, highly-optimized implementations.

The diff-based workflow built into editing tools provides immediate transparency. Colorized diffs make every change apparent to both users and the model itself, encouraging minimal modifications and enabling easy review and revert cycles. This transparency is fundamental to the system's debuggability—developers can follow the agent's logic, identify where things go wrong, and adjust approaches with full visibility into each modification.

## Planning and state management prevent context degradation

Claude Code implements sophisticated planning mechanisms to maintain focus during long-running tasks. The **TodoWrite tool** creates structured JSON task lists with IDs, content, status fields, and priority levels, which the UI renders as interactive checklists for user visibility. The system updates entire lists rather than making partial updates, transitioning items through "pending" → "in_progress" → "completed" states. Critically, after each tool execution, system messages automatically inject the current TODO list state to prevent "context rot" where agents lose track of objectives over extended conversations.

The `/think` command activates **Plan Mode**, a read-only state where Claude cannot create, modify, or delete files but can research and analyze the codebase comprehensively. This explicit separation between planning and execution enables more predictable workflows—Claude develops comprehensive strategies with structured steps, users review and approve plans before implementation, then the system switches to execution mode and implements the approved plan. This pattern leverages extended thinking capabilities for architectural decisions while maintaining user control over what actions are actually taken.

The **CLAUDE.md memory system** provides persistent project context across sessions through three hierarchical levels: project-level files in `.claude/CLAUDE.md` or the project root (checked into version control), user-level files in `~/.claude/CLAUDE.md` for personal preferences, and directory-level files in child directories fetched on-demand. According to Anthropic documentation, the performance difference with versus without CLAUDE.md is "night and day," as these files codify project conventions, coding standards, frequently used commands, and project-specific terminology that cannot be inferred from the codebase alone. Contents are sent with every user request, providing consistent context grounding.

## Sub-agents enable controlled parallelization without context pollution

Custom sub-agents in Claude Code function as specialized AI assistants invoked for specific task types, enabling efficient problem-solving through task-specific configurations. Each sub-agent operates with **isolated context windows**, custom system prompts for specialized behavior, and selective tool access—either inheriting all tools or having restricted capabilities. Claude proactively delegates appropriate tasks to sub-agents without explicit user instruction, and importantly, sub-agents lack self-awareness—they receive the same system prompt as the main agent and don't know they're operating as sub-agents.

Sub-agents are defined as Markdown files with YAML frontmatter, stored in `.claude/agents/` for project-level sharing with teams or `~/.claude/agents/` for personal use. Configuration fields include a unique name identifier, natural language description (critical for Claude's selection logic), comma-separated tool lists, and model specification (sonnet/opus/haiku or 'inherit'). Project sub-agents take priority over user sub-agents when naming conflicts occur.

The architectural constraint limiting **maximum one branch at a time** with depth limitations prevents uncontrolled proliferation—sub-agents cannot spawn their own sub-agents. This controlled parallelization provides the benefits of specialized, focused work without the debugging complexity of multi-agent swarms. As Anthropic's official documentation states: "Each sub-agent operates in its own context, preventing pollution of the main conversation and keeping it focused on high-level objectives." Common use cases include wide searches across codebases, trying multiple solution approaches, isolated task execution, and specialized analysis like code reviews or testing.

## Decision-making flows through explicit algorithms in the system prompt

Claude Code encodes its decision-making logic through approximately **2,800 tokens of system prompt** plus the 9,400-token tool definitions, structured into sections covering tone and style, proactiveness, convention following, code style, task management, tool use policy, and task execution guidelines. The prompt engineering approach writes out explicit algorithms rather than providing "big soups of Dos and Don'ts," with developers role-playing as the LLM to work through examples and identify all decision points.

XML tags structure critical information for the model. The `<system-reminder>` tag reminds the LLM of information it might forget, `<good-example>` and `<bad-example>` tags codify heuristics for fork-in-road decisions, and `<thinking>` tags enable interleaved reasoning during execution. Emphasis markers like "IMPORTANT," "VERY IMPORTANT," "NEVER," and "ALWAYS" appear liberally throughout the prompt—Anthropic acknowledges these remain state-of-the-art until models become more inherently steerable.

For example, a critical instruction reads: "VERY IMPORTANT: You MUST avoid using search commands like `find` and `grep`. Instead use Grep, Glob, or Task to search." This explicit prohibition prevents the model from defaulting to low-level bash commands when dedicated tools provide better accuracy. The system prompt identifies specific decision points with heuristics, uses flow-chart style structuring to aid in following instructions, and provides concrete examples for various scenarios to make the decision tree as clear as possible.

When analyzing tasks, Claude follows a structured assessment process: parsing the user request, determining complexity level, deciding between direct implementation versus planning first versus sub-agent delegation, checking TODO list status, and reviewing available context and tools. For planning-worthy tasks—those involving multi-step coordination, complex refactoring, many dependencies, or explicit user requests—the output includes structured TODO lists with priorities, file-by-file edit plans, test strategies, concrete command lists, and risk identification.

## Model selection optimizes costs through strategic delegation

Over **50% of important LLM calls** use claude-3-5-haiku, the smaller model, for routine operations including reading large files, parsing web pages, processing git history, summarizing long conversations, and even generating one-word processing labels for every keystroke. This strategic model selection provides 70-80% cost reduction compared to Sonnet 4 or GPT-4.1 while maintaining performance for tasks that don't require the most sophisticated reasoning capabilities.

The architecture reserves powerful models like Claude Sonnet for standard complexity tasks and Opus for the most challenging reasoning problems, while Haiku handles the high-frequency, lower-complexity operations that make up the majority of agent loop cycles. This multi-model strategy enables Claude Code to operate efficiently at scale, with the automatic compaction system using smaller models for summarization when context windows approach capacity.

Context window management triggers automatically at approximately **92% usage** through the "wU2" compressor component. The system summarizes previous conversations, moves important information to long-term storage in CLAUDE.md files, and enables agents to run indefinitely without context exhaustion. Users can also manually trigger compaction with the `/compact` command, specifying which information to preserve, or use `/clear` to reset context between distinct tasks. This prevents "context rot" where agents gradually lose focus during extended sessions.

## Error handling combines automatic recovery with user control

Claude Code implements comprehensive error handling at multiple architectural layers. The SDK defines specific error types including ClaudeSDKError as the base exception, CLINotFoundError when Claude Code isn't installed, CLIConnectionError for connectivity issues, ProcessError when processes fail (including exit codes), and CLIJSONDecodeError for parsing problems. These typed exceptions enable programmatic error handling in automated workflows.

The agent loop's feedback mechanism enables sophisticated self-correction through three primary approaches. **Rules-based feedback** provides clearly defined output rules, explaining which rules failed and why—code linting exemplifies this with multiple validation layers, and TypeScript offers more feedback opportunities than JavaScript. **Test-driven development** creates automatic validation loops where tests run after changes, failures are analyzed, and iterations continue until all tests pass. **Validation checks** catch errors before they compound, including email address validation, user history verification before sending, and custom business logic enforcement.

When errors occur, recovery strategies include backtracking to the last known good state, trying alternative solution approaches, spawning sub-agents for fresh perspectives, or requesting clarification from users. For rate limiting and API issues, the system implements exponential backoff for timeout recovery, monitors X-RateLimit-* headers, implements request queuing, and uses token bucket algorithms for request throttling. Circuit breaker patterns prevent cascading failures with configurable timeout thresholds, error percentage limits, reset timeouts, and request volume requirements.

Known failure modes include infinite compaction loops where the system repeatedly reads the same files attempting to compact context, self-termination when using broad process kill commands like `pkill node` that terminate Claude Code itself, and context window exhaustion leading to usage limits. Best practices recommend frequent context resets between tasks, scoping conversations to single projects or features, and using `/clear` commands to maintain focus.

## Loop termination uses natural and programmatic signals

The primary termination condition is elegantly simple: **the loop continues as long as Claude's response includes tool usage and terminates naturally when Claude produces plain text without tool calls**. This natural termination requires no explicit commands—when Claude determines the task is complete and formulates a final answer, the absence of tool calls signals the loop to stop, cleanly returning control to the user for the next input.

For programmatic and automated contexts, Claude Code's headless mode (`claude -p` or `claude --print`) enables non-interactive execution in CI/CD pipelines, GitHub Actions, build scripts, and scheduled automation. In these contexts, responses can specify explicit success or failure strings—for example, instructing Claude: "you MUST return the string OK if you succeeded, or FAIL if the task failed." Exit codes then determine programmatic success or failure for integration into larger workflows.

Advanced autonomous systems detect completion through multiple signals. The Ralph autonomous development loop project, for instance, implements detection for all tasks in planning documents marked complete, multiple consecutive "done" signals from Claude Code, too many test-focused loops indicating feature completeness, and strong completion indicators in natural language responses. Rate limiting mechanisms (configurable, defaulting to 100 calls/hour with hourly resets) and circuit breakers for error detection provide additional termination safeguards.

Edge cases and known issues include the aforementioned infinite compaction loops, self-termination from broad kill commands, and usage limit warnings when approaching API caps. Recent patches (v0.2.111 and v1.0.20) addressed path validation vulnerabilities CVE-2025-54794 and CVE-2025-54795, which used naive prefix-based approaches that could be exploited. Weekly usage caps were added after some users ran Claude Code continuously for 24/7 operations.

## Safety mechanisms layer permissions and sandboxing

Claude Code implements multi-layered protection through a sophisticated permission system. Write operations require explicit approval by default, risky Bash commands trigger confirmation prompts, and external tool usage through MCP or web access requires allow/deny decisions. Users configure fine-grained rules in `.claude/settings.json` specifying allowed and denied operations, such as `"allow": ["Bash(npm run test:*)", "Read(~/.zshrc)"]` and `"deny": ["Bash(curl:*)", "Read(./.env)"]`.

Permission modes range from the default "ask" requiring approval for every action, to "acceptEdits" auto-approving file edits only, to "acceptTools" auto-approving specific tool categories, to custom rules for precise control. The `--dangerously-skip-permissions` flag enables "YOLO mode" bypassing all checks—a mode that should only be used in controlled sandbox environments. Commands receive risk level classifications with safety notes appended to tool outputs, reminding both the model and user of potential dangers.

Command sanitization prevents injection attacks by blocking backticks and `$()` constructs, using fail-closed matching where unmatched commands default to requiring manual approval, and flagging suspicious commands even if previously allowlisted. Anthropic's official documentation strongly emphasizes the security implications: "You must consider the security implication of hooks as you add them, because hooks run automatically during the agent loop with your current environment's credentials."

While Claude Code lacks built-in sandboxing and runs locally with user permissions by default, community solutions provide isolation through Docker containers (claude-code-sandbox, cco projects), E2B cloud sandbox integration, VM-based isolation, and process isolation preventing host system effects. Security best practices include running in containers without internet access, limiting filesystem access to block sensitive directories like ~/.ssh/ and ~/.aws/, using git worktrees for multiple isolated sessions, and never running as root.

## Hooks enable deterministic control over the agent lifecycle

The hooks system provides user-defined shell commands executing at specific points in Claude Code's lifecycle, offering deterministic control over behavior rather than relying on the LLM to choose to run certain operations. Available hook events include **PreToolUse** running before tool calls with the ability to block them, **PostToolUse** executing after tool completion, **SessionStart** triggering when sessions begin, and **SessionEnd** running at session termination.

Common use cases demonstrate the power of deterministic automation. Automatic code formatting runs prettier or gofmt after file modifications, command logging maintains compliance audit trails, custom permission controls add project-specific validation, automated notifications alert teams of significant changes, and feedback systems provide immediate guidance on code convention adherence. These hooks run automatically during the agent loop with current environment credentials, requiring careful security consideration.

Hooks are configured in `.claude/settings.json` or project-level configuration files, with shell commands specified for each event type. The deterministic nature is crucial for production deployments—teams can enforce that certain operations always happen (formatting, validation, logging) without depending on the LLM's judgment about when these operations are appropriate. This complements rather than replaces the agent's autonomous decision-making, providing guardrails and automation for operations requiring absolute consistency.

## MCP integration enables unlimited extensibility

The Model Context Protocol (MCP) integration allows Claude Code to access tools and data sources external to the base system through an open protocol. MCP servers operate at three scope levels: **local scope** for user-specific, project-level servers; **project scope** shared via `.mcp.json` and version controlled; and **global scope** available across all projects. This architecture enables database connectivity, API integrations, custom tool development, and enterprise system connections without modifying core Claude Code infrastructure.

Users configure allowed MCP servers in source code, either writing custom servers for their needs or using trusted providers from the ecosystem. Anthropic explicitly does not manage or audit MCP servers—the responsibility for security and reliability falls on users and server developers. Fine-grained permissions apply per MCP server, with the same allow/deny pattern used for built-in tools extending to external integrations.

MCP dramatically expands Claude Code's capabilities while maintaining the simple, single-threaded agent loop architecture. Rather than building every possible integration into the core system, MCP provides standardized interfaces for external capabilities. This enables specialized agents for domains like legal analysis, finance operations, or customer support that need access to enterprise systems, databases, or proprietary APIs while using the same proven agent harness and loop mechanics.

## Production features support enterprise deployment

The Claude Agent SDK, built on the same agent harness powering Claude Code, provides production-ready infrastructure for custom agents. Built-in capabilities include automatic context management with compaction preventing exhaustion, rich tool ecosystems with file operations and MCP extensibility, advanced permissions with fine-grained control, comprehensive error handling and session management, production monitoring and observability, and automatic prompt caching with performance optimizations.

GitHub Actions integration demonstrates enterprise readiness with intelligent mode detection requiring no configuration, PR and issue integration via `@claude` mentions, automated code review and implementation, progress tracking through dynamic checkboxes, and execution on customer infrastructure rather than Anthropic's servers. The headless mode enables CI/CD pipeline integration, pre-commit hooks, build script automation, and batch processing patterns.

The SDK supports diverse agent types including coding agents for SRE, security review, and code analysis; business agents for legal, finance, and customer support; content creation agents for marketing teams; and custom domain-specific agents. All leverage the same fundamental agent loop pattern—gather context, take action, verify work, repeat—with customization through system prompts, tool selections, and permission configurations rather than architectural changes.

Performance characteristics demonstrate production viability. Claude Code achieves state-of-the-art results on SWE-bench Verified for real-world software coding and 61.4% on OSWorld (up from 42.2% four months prior). The system maintains focus during long-running tasks observed at 30+ hours, achieves 0% error rates on internal edit accuracy benchmarks (down from 9% on Sonnet 4), and operates within a context window approaching 1 million tokens with automatic compaction at 92% usage.

## Architectural philosophy prioritizes simplicity and transparency

Claude Code's design represents a conscious rejection of complexity in favor of what Anthropic internally calls "Keep Things Simple, Dummy" (KTSD). The single-threaded design with flat message history avoids complex multi-agent swarms, regex is chosen over embeddings for search, Markdown files serve as memory rather than databases, and the system maintains debuggability over sophisticated orchestration. As one internal analysis articulates: "LLMs are terrible enough to debug and evaluate" without adding unnecessary architectural complexity.

This simplicity enables transparency at every level. Colorized diffs show every code change immediately, comprehensive logging creates complete audit trails, clear tool call sequences make reasoning visible, and the flat execution model allows developers to follow the agent's logic step-by-step. Users can identify exactly where things go wrong, adjust approaches with full context, and build trust through understanding rather than faith in black-box systems.

The philosophy extends to iteration over perfection. First attempts might be good, but 2-3 iterations produce significantly better results when provided with clear targets like tests, visual mocks, or output validation. Claude makes changes, evaluates results through the verification phase, and incrementally improves—a feedback loop that the architecture treats as fundamental rather than exceptional. This embrace of iteration acknowledges that autonomous agents work best when they can course-correct based on real feedback rather than attempting to plan perfectly upfront.

Anthropic's explicit design choice to provide "close to raw model access" means Claude Code remains intentionally low-level and unopinionated, not forcing specific workflows on users. The system is scriptable and composable, uses file-system based configuration accessible to standard development tools, and achieves extensibility through MCP rather than rigid built-in feature sets. This flexibility enables the same agent harness to power everything from simple one-off scripts to sophisticated autonomous coding sessions to production enterprise agents.

## Advanced patterns demonstrate architectural versatility

Test-driven development workflows showcase the agent loop's power. Developers ask Claude to write tests based on expected input/output pairs, instruct Claude to implement code passing those tests without modifying test specifications, and continue iterating until all tests pass. Optionally, independent sub-agents verify implementations aren't overfitting. This pattern treats tests as the source of truth and uses the agent loop's verification phase to drive quality—a multiplier effect where agentic coding makes TDD more powerful and vice versa.

Visual design iteration demonstrates similar principles. Developers provide Claude with screenshot capabilities through Puppeteer MCP or iOS simulator integration, supply visual mocks as images or file paths, and ask Claude to implement designs in code. The agent takes screenshots of results, compares them to mocks, and iterates until results match targets. This visual feedback loop enables UI development with pixel-perfect accuracy, something extremely difficult for LLMs to achieve without iterative correction.

Multiple agent coordination patterns enable sophisticated workflows. One Claude instance writes code while another reviews, or one writes tests while another implements to pass them. Separate working scratchpads facilitate inter-agent communication, and isolated contexts allow different concerns—strategic planning versus tactical implementation—to proceed without interference. These patterns leverage sub-agent architecture without violating the single main branch constraint.

Fan-out patterns for batch processing demonstrate headless mode capabilities. Scripts loop through large task lists, calling Claude programmatically for each item, handling migrations or analyses across thousands of files. Unlike interactive sessions, these automated workflows specify explicit success/failure detection, integrate with monitoring systems, and operate within CI/CD pipelines or scheduled jobs. The same agent loop mechanics that power interactive coding enable these production automation scenarios.

## Conclusion: constraint-driven design enables powerful autonomy

Claude Code's agent loop achieves sophisticated autonomous behavior not through architectural complexity but through careful constraint-driven design. The single-threaded master loop with natural termination conditions, comprehensive tooling mirroring developer workflows, built-in feedback mechanisms for self-correction, multi-layered safety through permissions and sandboxing, and automatic context management combine to create a system that balances capability with reliability.

The key technical innovation lies in the `while(tool_call)` pattern combined with intelligent tool selection, iterative verification, and transparent execution. This enables Claude Code to handle everything from simple code edits to complex multi-file refactoring projects while maintaining the debuggability and controllability essential for production use. The same architecture powers diverse applications—from the CLI tool developers use interactively to the Agent SDK enabling custom enterprise agents to headless automation in CI/CD pipelines.

Anthropic's design philosophy of simplicity over sophistication, transparency over opacity, and iteration over perfection has created an agent architecture that scales through disciplined tool design rather than architectural elaboration. As models continue improving, this simple foundation captures those gains directly rather than being limited by complex orchestration overhead. The agent loop's effectiveness ultimately demonstrates that **the most powerful autonomous systems often emerge from the simplest, most debuggable patterns** rather than sophisticated multi-agent architectures.